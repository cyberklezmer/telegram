# Get actual histogram
actual_df <- histograms_by_channel[[username]] |>
mutate(
bin_label = as.character(bin),
source = "Forwards"
) |>
rename(prob = prop, prob_low = lower, prob_high = upper)
# Ensure consistent bin ordering
bin_levels <- actual_df$bin_label
# Parse modeled terms like "alpha_1", "alpha_2", ...
modeled_df <- all_coefs_list[["all"]] |>
mutate(
bin_index = as.integer(gsub("alpha_", "", term)),
bin_label = bin_levels[bin_index],
source = "Views"
) |>
dplyr::select(bin_label, prob, prob_low, prob_high, source)
# Combine actual and modeled data
combined_df <- bind_rows(actual_df, modeled_df) |>
mutate(bin_label = factor(bin_label, levels = bin_levels))
# Plot with dodged bars for actual and modeled values
ggplot(combined_df, aes(x = bin_label, y = prob, fill = source)) +
geom_col(position = position_dodge(width = 0.9), width = 0.8) +
geom_errorbar(
aes(ymin = prob_low, ymax = prob_high),
position = position_dodge(width = 0.9),
width = 0.2
) +
labs(
title = username,
x = "Time delay bin",
y = "Probability"
) +
scale_fill_manual(values = c("Forwards" = "steelblue", "Views" = "red")) +
theme_minimal() +
theme(
plot.title = element_text(size = 10, face = "bold"),
axis.text.x = element_text(size = 6, angle = 45, hjust = 1),
axis.text.y = element_text(size = 6),
axis.title = element_text(size = 8),
plot.margin = margin(2, 2, 2, 2),
legend.position = "none"  # ‚ùå Hides the legend
)
}
# Ensure ggplot2 and grDevices are loaded
library(ggplot2)
library(grDevices)
library(patchwork)
# Generate all plots into a list
plot_list <- lapply(names(histograms_by_channel), plot_combined_histogram)
# Combine them into a grid with 3 columns
wrap_plots(plot_list, ncol = 3)
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
# must start at 0:0:0 !!!
#anal_start_str <- "2025-05-18 00:00:00"
anal_start_str <- "2025-02-28 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-05-25 23:59:59"
#anal_end_str <- "2025-02-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# take care, hole in data from 26.3 - 4.4.  !!!
# 0 nzst be first,
cs <- c(0,0.0625/2,0.0625,0.125,0.25,0.5,1,2,4,8,params$t_limit)
con <- connect_db()
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
# must start at 0:0:0 !!!
#anal_start_str <- "2025-05-18 00:00:00"
anal_start_str <- "2025-02-28 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-05-25 23:59:59"
#anal_end_str <- "2025-02-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# take care, hole in data from 26.3 - 4.4.  !!!
# 0 nzst be first,
cs <- c(0,0.0625/2,0.0625,0.125,0.25,0.5,1,2,4,8,params$t_limit)
con <- connect_db()
sqlstring <- sprintf(
"SELECT CH.username, RH.message_id, count, RH.TS, posted, IF(RH.reaction_emo = 'VIEWS','VIEWS',HEX(RH.reaction_emo)) AS emo, CH.quartile, IF(CH.sources LIKE '%%T%%' , 'C',CH.sources) as sources
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
INNER JOIN channels_info CH
ON RH.channel_id = CH.channel_id
#     WHERE RH.reaction_emo = 'VIEWS'
WHERE posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND CH.quartile = 4
" ,
anal_start_str, last_message_str, anal_end_str
)
reaction_data <- dbGetQuery(
con, sqlstring
)
# catalogue <- get_catalogue(con)
channel_info <- dbGetQuery(
con, "SELECT * FROM channels_info WHERE quartile = 4"
)
invisible(dbDisconnect(con))
reaction_data <- reaction_data %>%
mutate( sq = paste0(sources,quartile))
reaction_data <- reaction_data %>%
arrange(username, emo, message_id, TS) %>%
group_by(username, emo, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(username, message_id, TS) %>%
group_by(username, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S"),
daytime_last_ts = format(as.POSIXct(last_TS), "%H:%M:%S")
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600,
last_hour_of_day = hour(hms(daytime_last_ts)) +
minute(hms(daytime_last_ts)) / 60 +
second(hms(daytime_last_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(username,sources,quartile,sq,message_id,emo, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
usernames <- reaction_data |>
distinct(username) |>
pull(username)
sources <- reaction_data |>
distinct(sources) |>
pull(sources)
sqs <- reaction_data |>
distinct(sq) |>
pull(sq)
reaction_summary <- reaction_data %>%
group_by(channel_id) %>%
summarise(
n_rows = n(),
n_messages = n_distinct(message_id),
n_views = sum(emo == "VIEWS", na.rm = TRUE),
min_time_posted = min(time_posted, na.rm = TRUE),
max_time_posted = max(time_posted, na.rm = TRUE),
.groups = "drop"
)
reaction_summary <- reaction_data %>%
group_by(username) %>%
summarise(
n_rows = n(),
n_messages = n_distinct(message_id),
n_views = sum(emo == "VIEWS", na.rm = TRUE),
min_time_posted = min(time_posted, na.rm = TRUE),
max_time_posted = max(time_posted, na.rm = TRUE),
.groups = "drop"
)
channel_summary <- channel_info %>%
left_join(reaction_summary, by = "username")
print(channel_summary)
View(channel_summary)
write.csv(channel_summary,"chas.csv")
sqlstring
con <- connect_db()
sqlstring <- sprintf(
"SELECT CH.username, RH.message_id, count, RH.TS, posted, IF(RH.reaction_emo = 'VIEWS','VIEWS',HEX(RH.reaction_emo)) AS emo, CH.quartile, IF(CH.sources LIKE '%%T%%' , 'C',CH.sources) as sources
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
INNER JOIN channels_info CH
ON RH.channel_id = CH.channel_id
WHERE posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND CH.quartile = 4
" ,
anal_start_str, last_message_str, anal_end_str
)
reaction_data <- dbGetQuery(
con, sqlstring
)
# catalogue <- get_catalogue(con)
channel_info <- dbGetQuery(
con, "SELECT * FROM channels_info WHERE quartile = 4"
)
invisible(dbDisconnect(con))
reaction_data <- reaction_data %>%
mutate( sq = paste0(sources,quartile))
reaction_data <- reaction_data %>%
arrange(username, emo, message_id, TS) %>%
group_by(username, emo, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(username, message_id, TS) %>%
group_by(username, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S"),
daytime_last_ts = format(as.POSIXct(last_TS), "%H:%M:%S")
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600,
last_hour_of_day = hour(hms(daytime_last_ts)) +
minute(hms(daytime_last_ts)) / 60 +
second(hms(daytime_last_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(username,sources,quartile,sq,message_id,emo, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
library(dplyr)
# Summarise reaction_data by channel_id
reaction_summary <- reaction_data %>%
group_by(username) %>%
summarise(
n_rows = n(),
n_messages = n_distinct(message_id),
n_views = sum(emo == "VIEWS", na.rm = TRUE),
min_time_posted = min(time_posted, na.rm = TRUE),
max_time_posted = max(time_posted, na.rm = TRUE),
.groups = "drop"
)
# Join the summary back to channel_info (left join to keep all channel_info rows)
channel_summary <- channel_info %>%
left_join(reaction_summary, by = "username")
# View the resulting data frame
print(channel_summary)
usernames <- reaction_data |>
distinct(username) |>
pull(username)
sources <- reaction_data |>
distinct(sources) |>
pull(sources)
sqs <- reaction_data |>
distinct(sq) |>
pull(sq)
write.csv(channel_summary,"chas.csv")
con <- connect_db()
sqlstring <- sprintf(
"SELECT CH.username, RH.message_id, count, RH.TS, posted, IF(RH.reaction_emo = 'VIEWS','VIEWS',HEX(RH.reaction_emo)) AS emo, CH.quartile, IF(CH.sources LIKE '%%T%%' , 'C',CH.sources) as sources
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
INNER JOIN channels_info CH
ON RH.channel_id = CH.channel_id
WHERE posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND CH.quartile = 4 AND
username = 'crypto_insider_deutscher'
" ,
anal_start_str, last_message_str, anal_end_str
)
reaction_data <- dbGetQuery(
con, sqlstring
)
nrow(reaction_data)
con <- connect_db()
sqlstring <- sprintf(
"SELECT CH.username, RH.message_id, count, RH.TS, posted, IF(RH.reaction_emo = 'VIEWS','VIEWS',HEX(RH.reaction_emo)) AS emo, CH.quartile, IF(CH.sources LIKE '%%T%%' , 'C',CH.sources) as sources
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
INNER JOIN channels_info CH
ON RH.channel_id = CH.channel_id
WHERE posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND CH.quartile = 4 AND
username = 'crypto_insider_deutscher'
" ,
anal_start_str, last_message_str, anal_end_str
)
reaction_data <- dbGetQuery(
con, sqlstring
)
# catalogue <- get_catalogue(con)
channel_info <- dbGetQuery(
con, "SELECT * FROM channels_info WHERE quartile = 4"
)
invisible(dbDisconnect(con))
reaction_data <- reaction_data %>%
mutate( sq = paste0(sources,quartile))
reaction_data <- reaction_data %>%
arrange(username, emo, message_id, TS) %>%
group_by(username, emo, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(username, message_id, TS) %>%
group_by(username, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S"),
daytime_last_ts = format(as.POSIXct(last_TS), "%H:%M:%S")
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600,
last_hour_of_day = hour(hms(daytime_last_ts)) +
minute(hms(daytime_last_ts)) / 60 +
second(hms(daytime_last_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(username,sources,quartile,sq,message_id,emo, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
library(dplyr)
# Summarise reaction_data by channel_id
reaction_summary <- reaction_data %>%
group_by(username) %>%
summarise(
n_rows = n(),
n_messages = n_distinct(message_id),
n_views = sum(emo == "VIEWS", na.rm = TRUE),
min_time_posted = min(time_posted, na.rm = TRUE),
max_time_posted = max(time_posted, na.rm = TRUE),
.groups = "drop"
)
# Join the summary back to channel_info (left join to keep all channel_info rows)
channel_summary <- channel_info %>%
left_join(reaction_summary, by = "username")
# View the resulting data frame
print(channel_summary)
usernames <- reaction_data |>
distinct(username) |>
pull(username)
sources <- reaction_data |>
distinct(sources) |>
pull(sources)
sqs <- reaction_data |>
distinct(sq) |>
pull(sq)
channel_summary
View(reaction_data)
con <- connect_db()
sqlstring <- sprintf(
"SELECT CH.username, RH.message_id, count, RH.TS, posted, IF(RH.reaction_emo = 'VIEWS','VIEWS',HEX(RH.reaction_emo)) AS emo, CH.quartile, IF(CH.sources LIKE '%%T%%' , 'C',CH.sources) as sources
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
INNER JOIN channels_info CH
ON RH.channel_id = CH.channel_id
WHERE posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND CH.quartile = 4 AND
username = 'crypto_insider_deutscher'
" ,
anal_start_str, last_message_str, anal_end_str
)
reaction_data <- dbGetQuery(
con, sqlstring
)
# catalogue <- get_catalogue(con)
channel_info <- dbGetQuery(
con, "SELECT * FROM channels_info WHERE quartile = 4"
)
invisible(dbDisconnect(con))
reaction_data <- reaction_data %>%
mutate( sq = paste0(sources,quartile))
reaction_data <- reaction_data %>%
arrange(username, emo, message_id, TS) %>%
group_by(username, emo, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(username, message_id, TS) %>%
group_by(username, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S"),
daytime_last_ts = format(as.POSIXct(last_TS), "%H:%M:%S")
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600,
last_hour_of_day = hour(hms(daytime_last_ts)) +
minute(hms(daytime_last_ts)) / 60 +
second(hms(daytime_last_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(username,sources,quartile,sq,message_id,emo, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
# Summarise reaction_data by channel_id
reaction_summary <- reaction_data %>%
group_by(username) %>%
summarise(
n_rows = n(),
n_messages = n_distinct(message_id),
n_views = sum(emo == "VIEWS", na.rm = TRUE),
min_time_posted = min(time_posted, na.rm = TRUE),
max_time_posted = max(time_posted, na.rm = TRUE),
.groups = "drop"
)
View(reaction_summary)
View(channel_info)
channel_summary <- channel_info %>%
left_join(reaction_summary, by = "username")
con <- connect_db()
sqlstring <- sprintf(
"SELECT CH.username, RH.message_id, count, RH.TS, posted, IF(RH.reaction_emo = 'VIEWS','VIEWS',HEX(RH.reaction_emo)) AS emo, CH.quartile, IF(CH.sources LIKE '%%T%%' , 'C',CH.sources) as sources
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
INNER JOIN channels_info CH
ON RH.channel_id = CH.channel_id
WHERE posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND CH.quartile = 4
" ,
anal_start_str, last_message_str, anal_end_str
)
# AND   username = 'crypto_insider_deutscher'
reaction_data <- dbGetQuery(
con, sqlstring
)
# catalogue <- get_catalogue(con)
channel_info <- dbGetQuery(
con, "SELECT * FROM channels_info WHERE quartile = 4"
)
invisible(dbDisconnect(con))
reaction_data <- reaction_data %>%
mutate( sq = paste0(sources,quartile))
reaction_data <- reaction_data %>%
arrange(username, emo, message_id, TS) %>%
group_by(username, emo, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(username, message_id, TS) %>%
group_by(username, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S"),
daytime_last_ts = format(as.POSIXct(last_TS), "%H:%M:%S")
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600,
last_hour_of_day = hour(hms(daytime_last_ts)) +
minute(hms(daytime_last_ts)) / 60 +
second(hms(daytime_last_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(username,sources,quartile,sq,message_id,emo, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
# Summarise reaction_data by channel_id
reaction_summary <- reaction_data %>%
group_by(username) %>%
summarise(
n_rows = n(),
n_messages = n_distinct(message_id),
n_views = sum(emo == "VIEWS", na.rm = TRUE),
min_time_posted = min(time_posted, na.rm = TRUE),
max_time_posted = max(time_posted, na.rm = TRUE),
.groups = "drop"
)
# Join the summary back to channel_info (left join to keep all channel_info rows)
channel_summary <- channel_info %>%
left_join(reaction_summary, by = "username")
# View the resulting data frame
print(channel_summary)
usernames <- reaction_data |>
distinct(username) |>
pull(username)
sources <- reaction_data |>
distinct(sources) |>
pull(sources)
sqs <- reaction_data |>
distinct(sq) |>
pull(sq)
write.csv(channel_summary,"chas.csv")
