}
# Check X
X <- as.data.frame(X)
colnames(X) <- paste0("alpha_", seq_len(k))
# Merge X with Y
model_data <- bind_cols(regr_data, X)
library(purrr)
# Get names of covariates (columns starting with "alpha_")
alpha_vars <- grep("^alpha_", names(model_data), value = TRUE)
# Check if any row has Y > 0 and all alpha_ variables equal to zero
n_rows_ypos_zero_alpha <- model_data %>%
filter(Y > 0) %>%
filter(if_all(all_of(alpha_vars), ~ .x == 0)) %>%
nrow()
if(n_rows_ypos_zero_alpha > 0)
{
stop("Number of rows with Y > 0 and all alpha_* == 0:", n_rows_ypos_zero_alpha, "\n")
}
# Count for each alpha_* variable the number of rows where it is non-zero
nonzero_counts <- model_data %>%
summarise(across(all_of(alpha_vars), ~ sum(. != 0)))
print(nonzero_counts)
ols_model <- lm(Y ~ . - r - s + 0, data = model_data)
summary(ols_model)
library(broom)
library(ggplot2)
library(dplyr)
residuals <- resid(ols_model)
fitted_vals <- fitted(ols_model)
# Calculate weights using the absolute value
weights <- 1 / (abs(fitted_vals))
wls_model <- lm(Y ~ . - r - s + 0, data = model_data, weights = weights)
summary(wls_model)
# Step 1: Extract WLS model coefficients and CIs
coefs_df <- broom::tidy(wls_model, conf.int = TRUE) %>%
filter(grepl("^alpha_", term))
# Step 2: Attach x-axis labels cs[2:(k+1)] as categorical variable
k <- length(cs) - 1
cs_labels <- cs[2:(k + 1)]
# Format cs labels (optional: round or pretty format)
cs_labels_formatted <- format(round(cs_labels, 2), nsmall = 2)
# Add labels to coefficients data
coefs_df <- coefs_df %>%
mutate(
cs_label = factor(cs_labels_formatted, levels = cs_labels_formatted)
)
# Step 3: Plot equidistant bar chart
ggplot(coefs_df, aes(x = cs_label, y = estimate)) +
geom_bar(stat = "identity", fill = "steelblue", width = 0.8) +
geom_errorbar(
aes(ymin = conf.low, ymax = conf.high),
width = 0.2,
color = "black"
) +
labs(
x = "Interval Upper Bound (cs[2] to cs[k+1])",
y = "WLS Coefficient Estimate",
title = "WLS Estimates for Interval Coefficients"
) +
theme_minimal(base_size = 14)
View(reaction_data)
seasonal_model
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
anal_start_str <- "2025-02-22 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-04-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# 0 nzst be first,
cs <- c(0,0.125,0.25,0.5,1,2,4,8,params$t_limit)
seasonal_model <- lm(delta_count ~ hour_bin, data = reaction_data)
seasonal_model
hourly_result <- get_hourly_levels(seasonal_model)
hourly_result
norm_c <- 1 /sum(hourly_result$values) * length(hourly_result$values)
norm_c
hourly_result$values <- hourly_result$values * norm_c
hourly_result$se <-hourly_result$se * norm_c
hourly_result
hourly_result <- get_hourly_levels(seasonal_model)
sum(hourly_result$values)
length(hourly_result$values)
hourly_values <- hourly_result$values
hourly_ses    <- hourly_result$se
hourly_result <- get_hourly_levels(seasonal_model)
# Access components
norm_c <- 1 /sum(hourly_result$values) * length(hourly_result$values)
hourly_result$values <- hourly_result$values * norm_c
hourly_result$se <-hourly_result$se * norm_c
hourly_values <- hourly_result$values
hourly_ses    <- hourly_result$se
hourly_result
hour_df <- data.frame(
hour = 0:23,
estimate = as.numeric(hourly_values),
se = as.numeric(hourly_ses)
) %>%
mutate(
ci_lower = estimate - 1.96 * se,
ci_upper = estimate + 1.96 * se
)
hourly_df
hour_df
ggplot(hour_df, aes(x = factor(hour), y = estimate)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.3) +
labs(
title = "Hourly Seasonality Pattern with 95% CI",
x = "Hour of Day",
y = "Estimated delta_count"
) +
theme_minimal()
hour_df
seasonal_model
hourly_result
hourly_values
hour_df
View(hour_df)
ggplot(hour_df, aes(x = factor(hour), y = estimate)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.3) +
labs(
title = "Hourly Seasonality Pattern with 95% CI",
x = "Hour of Day",
y = "Estimated delta_count"
) +
theme_minimal()
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
anal_start_str <- "2025-02-22 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-04-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# 0 nzst be first,
cs <- c(0,0.125,0.25,0.5,1,2,4,8,params$t_limit)
con <- connect_db()
reaction_data <- dbGetQuery(
con,
sprintf(
"SELECT RH.channel_id, RH.message_id, count, RH.TS, posted
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
WHERE RH.reaction_emo = 'VIEWS'
AND posted > '%s'
AND posted < '%s'
AND TS <= '%s'
#     AND RH.message_id = 3200
",
anal_start_str, last_message_str, anal_end_str
)
)
dbDisconnect(con)
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S")  # Extract time of day
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(channel_id,message_id, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
print(hour_df)
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
anal_start_str <- "2025-02-22 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-04-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# 0 nzst be first,
cs <- c(0,0.125,0.25,0.5,1,2,4,8,params$t_limit)
con <- connect_db()
reaction_data <- dbGetQuery(
con,
sprintf(
"SELECT RH.channel_id, RH.message_id, count, RH.TS, posted
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
WHERE RH.reaction_emo = 'VIEWS'
AND posted > '%s'
AND posted < '%s'
AND TS <= '%s'
#     AND RH.message_id = 3200
",
anal_start_str, last_message_str, anal_end_str
)
)
dbDisconnect(con)
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S")  # Extract time of day
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(channel_id,message_id, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
library(splines)
# --- Piece-wise linear model ---
reaction_data <- reaction_data %>%
mutate(hour_bin = cut(hour_of_day, breaks = 0:24, right = FALSE, include.lowest = TRUE))
seasonal_model <- lm(delta_count ~ hour_bin, data = reaction_data)
# Generate prediction data and intervals
# Extract hourly coefficients from the fitted model (run ONCE)
# Extract fitted hourly step values and their SEs
get_hourly_levels <- function(model) {
# Define hour bins (0â€“23, midpoint for safety)
hour_seq <- 0:23 + 0.5
hour_df <- data.frame(
hour_of_day = hour_seq,
hour_bin = cut(hour_seq, breaks = 0:24, right = FALSE, include.lowest = TRUE)
)
# Predict with standard errors
pred <- predict(model, newdata = hour_df, se.fit = TRUE)
# Prepare named vectors
values <- setNames(pred$fit, levels(hour_df$hour_bin))
ses    <- setNames(pred$se.fit, levels(hour_df$hour_bin))
list(values = values, se = ses)
}
hourly_result <- get_hourly_levels(seasonal_model)
# Access components
norm_c <- 1 /sum(hourly_result$values) * length(hourly_result$values)
hourly_result$values <- hourly_result$values * norm_c
hourly_result$se <-hourly_result$se * norm_c
hourly_values <- hourly_result$values
hourly_ses    <- hourly_result$se
# Build data frame for plotting
hour_df <- data.frame(
hour = 0:23,
estimate = as.numeric(hourly_values),
se = as.numeric(hourly_ses)
) %>%
mutate(
ci_lower = estimate - 1.96 * se,
ci_upper = estimate + 1.96 * se
)
print(hour_df)
# Bar plot with error bars
ggplot(hour_df, aes(x = factor(hour), y = estimate)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.3) +
labs(
title = "Hourly Seasonality Pattern with 95% CI",
x = "Hour of Day",
y = "Estimated delta_count"
) +
theme_minimal()
summary(seasonal_model)
nrow(reaction_data)
con <- connect_db()
reaction_data <- dbGetQuery(
con,
sprintf(
"SELECT RH.channel_id, RH.message_id, count, RH.TS, posted
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
WHERE RH.reaction_emo = 'VIEWS'
AND posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND RH.message_id = 7621
",
anal_start_str, last_message_str, anal_end_str
)
)
dbDisconnect(con)
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
anal_start_str <- "2025-02-22 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-04-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# take care, hole in data from 26.3 - 4.4.  !!!
# 0 nzst be first,
cs <- c(0,0.125,0.25,0.5,1,2,4,8,params$t_limit)
seasonal_data <- reaction_data %>%
filter(time_ts - time_last_ts < 1)
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
anal_start_str <- "2025-02-22 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-04-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# take care, hole in data from 26.3 - 4.4.  !!!
# 0 nzst be first,
cs <- c(0,0.125,0.25,0.5,1,2,4,8,params$t_limit)
con <- connect_db()
reaction_data <- dbGetQuery(
con,
sprintf(
"SELECT RH.channel_id, RH.message_id, count, RH.TS, posted
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
WHERE RH.reaction_emo = 'VIEWS'
AND posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND RH.message_id = 7621
",
anal_start_str, last_message_str, anal_end_str
)
)
dbDisconnect(con)
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S")  # Extract time of day
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(channel_id,message_id, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
anal_start_str <- "2025-02-22 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-04-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# take care, hole in data from 26.3 - 4.4.  !!!
# 0 nzst be first,
cs <- c(0,0.125,0.25,0.5,1,2,4,8,params$t_limit)
con <- connect_db()
reaction_data <- dbGetQuery(
con,
sprintf(
"SELECT RH.channel_id, RH.message_id, count, RH.TS, posted
FROM reactions_history RH
INNER JOIN messages M
ON RH.channel_id = M.channel_id AND RH.message_id = M.msg_id
WHERE RH.reaction_emo = 'VIEWS'
AND posted > '%s'
AND posted < '%s'
AND TS <= '%s'
AND RH.message_id = 7621
",
anal_start_str, last_message_str, anal_end_str
)
)
dbDisconnect(con)
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(delta_count = count - lag(count, default = 0),
last_TS = lag(TS))  %>%
ungroup()
reaction_data <- reaction_data %>%
arrange(channel_id, message_id, TS) %>%
group_by(channel_id, message_id) %>%
mutate(
posted_local = with_tz(force_tz(as.POSIXct(posted, tz = "GMT"), "GMT"), "Europe/Prague"),
time_posted = as.numeric(difftime(as.POSIXct(posted_local), anal_start, units = "hours")) ,
time_ts = as.numeric(difftime(as.POSIXct(TS), anal_start, units = "hours")))%>%
mutate(
time_last_ts = ifelse(is.na(last_TS),time_posted, as.numeric(difftime(as.POSIXct(last_TS), anal_start, units = "hours"))),
#    daytime = format(as.POSIXct(posted_local), "%H:%M:%S"),  # Extract time of day
daytime_ts = format(as.POSIXct(TS), "%H:%M:%S")  # Extract time of day
) %>%
mutate(
hour_of_day = hour(hms(daytime_ts)) +
minute(hms(daytime_ts)) / 60 +
second(hms(daytime_ts)) / 3600
)  %>%
ungroup() %>%
dplyr::select(channel_id,message_id, delta_count, posted,TS,time_posted,time_ts, time_last_ts, hour_of_day)
library(splines)
# --- Piece-wise linear model ---
reaction_data <- reaction_data %>%
mutate(hour_bin = cut(hour_of_day, breaks = 0:24, right = FALSE, include.lowest = TRUE))
seasonal_data <- reaction_data %>%
filter(time_ts - time_last_ts < 1)
seasonal_model <- lm(delta_count ~ hour_bin, data = seasonal_data)
# Generate prediction data and intervals
# Extract hourly coefficients from the fitted model (run ONCE)
# Extract fitted hourly step values and their SEs
get_hourly_levels <- function(model) {
# Define hour bins (0â€“23, midpoint for safety)
hour_seq <- 0:23 + 0.5
hour_df <- data.frame(
hour_of_day = hour_seq,
hour_bin = cut(hour_seq, breaks = 0:24, right = FALSE, include.lowest = TRUE)
)
# Predict with standard errors
pred <- predict(model, newdata = hour_df, se.fit = TRUE)
# Prepare named vectors
values <- setNames(pred$fit, levels(hour_df$hour_bin))
ses    <- setNames(pred$se.fit, levels(hour_df$hour_bin))
list(values = values, se = ses)
}
hourly_result <- get_hourly_levels(seasonal_model)
# Access components
norm_c <- 1 /sum(hourly_result$values) * length(hourly_result$values)
hourly_result$values <- hourly_result$values * norm_c
hourly_result$se <-hourly_result$se * norm_c
hourly_values <- hourly_result$values
hourly_ses    <- hourly_result$se
# Build data frame for plotting
hour_df <- data.frame(
hour = 0:23,
estimate = as.numeric(hourly_values),
se = as.numeric(hourly_ses)
) %>%
mutate(
ci_lower = estimate - 1.96 * se,
ci_upper = estimate + 1.96 * se
)
print(hour_df)
# Bar plot with error bars
ggplot(hour_df, aes(x = factor(hour), y = estimate)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.3) +
labs(
title = "Hourly Seasonality Pattern with 95% CI",
x = "Hour of Day",
y = "Estimated delta_count"
) +
theme_minimal()
nrow(reaction_data)
source("defs.R")
library(lubridate)
library(purrr)
library(ggplot2)
library(MASS)
anal_start_str <- "2025-02-22 00:00:00"
anal_start <- as.POSIXct(anal_start_str)
anal_end_str <- "2025-04-28 23:59:59"
anal_end <- as.POSIXct(anal_end_str)
last_message_str <- anal_end_str
last_messages<- as.POSIXct(last_message_str)
# take care, hole in data from 26.3 - 4.4.  !!!
# 0 nzst be first,
cs <- c(0,0.125,0.25,0.5,1,2,4,8,params$t_limit)
